<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>斐波那契数列算法总结</title>
    <url>/2024/04/01/%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E6%95%B0%E5%88%97%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h3 id="斐波那契数列">斐波那契数列：</h3>
<p><span class="math inline">\(\begin{cases}
0, &amp; \text{  } n=0 \\
1,&amp; \text{  } n=1,2 \\
f(n-1)+f(n-2), &amp; \text{  } n&gt;2
\end{cases}\)</span></p>
<h4 id="方法一朴素递归">方法一、朴素递归</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">fib</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (n==<span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (n==<span class="number">1</span> || n==<span class="number">2</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">fib</span>(n<span class="number">-1</span>) + <span class="built_in">fib</span>(n<span class="number">-2</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>斐波那契数列的通项公式为：$f(n)= $</p>
<p><img src="/2024/04/01/斐波那契数列算法总结/image-20240401221016279.png"  alt="image-20240401221016279" style="zoom: 55%;" /></p>
<p>如图所示，递归计算的终点都是<span
class="math inline">\(fib(1)\)</span>和<span
class="math inline">\(fib(2)\)</span>，因为它们是直接返回的，因此计算<span
class="math inline">\(fib(n)\)</span>的时间复杂度为计算<span
class="math inline">\(fib(1)\)</span>和<span
class="math inline">\(fib(2)\)</span>的次数，同时也等于<span
class="math inline">\(fib(n)\)</span>本身，因此<span
class="math inline">\(T(n)=O(fib(n))=O(\frac{1}{\sqrt{5}} \left [
(\frac{1+\sqrt[]{5} }{2} )^{n}- (\frac{1-\sqrt[]{5} }{2} )^{n}\right
])=O((\frac{1+\sqrt[]{5} }{2}
)^{n})\)</span>，第二项绝对值小于1，为<span
class="math inline">\(n\)</span>阶无穷小，可舍去，空间复杂度为函数调用栈的高度<span
class="math inline">\(n\)</span>,即<span
class="math inline">\(S(n)=O(n)\)</span>。</p>
<h4 id="方法二尾递归">方法二、尾递归</h4>
<p>首先需要清楚递归和尾递归的区别：</p>
<ul>
<li>1.递归：在调用函数自身后还有事要做，需要保存当前轮次的环境，以供后续返回时使用；</li>
</ul>
<p>如计算自然数前<span class="math inline">\(n\)</span>项和的函数<span
class="math inline">\(sum(n)\)</span>,递归实现方式如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">sum</span><span class="params">(n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (n==<span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> n + <span class="built_in">sum</span>(n<span class="number">-1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里的“+",即前面所说”还要做的事“，其计算过程如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sum</span>(<span class="number">5</span>)</span><br><span class="line"><span class="number">5</span> + <span class="built_in">sum</span>(<span class="number">4</span>)</span><br><span class="line"><span class="number">5</span> + (<span class="number">4</span> + <span class="built_in">sum</span>(<span class="number">3</span>))</span><br><span class="line"><span class="number">5</span> + (<span class="number">4</span> + (<span class="number">3</span> + <span class="built_in">sum</span>(<span class="number">2</span>)))</span><br><span class="line"><span class="number">5</span> + (<span class="number">4</span> + (<span class="number">3</span> + (<span class="number">2</span> + <span class="built_in">sum</span>(<span class="number">1</span>))))</span><br><span class="line"><span class="number">5</span> + (<span class="number">4</span> + (<span class="number">3</span> + (<span class="number">2</span> + (<span class="number">1</span> + <span class="built_in">sum</span>(<span class="number">0</span>)))))</span><br><span class="line"><span class="number">5</span> + (<span class="number">4</span> + (<span class="number">3</span> + (<span class="number">2</span> + (<span class="number">1</span> + <span class="number">0</span>))))</span><br><span class="line"><span class="number">5</span> + (<span class="number">4</span> + (<span class="number">3</span> + (<span class="number">2</span> + <span class="number">1</span>)))</span><br><span class="line"><span class="number">5</span> + (<span class="number">4</span> + (<span class="number">3</span> + <span class="number">3</span>))</span><br><span class="line"><span class="number">5</span> + (<span class="number">4</span> + <span class="number">6</span>)</span><br><span class="line"><span class="number">5</span> + <span class="number">10</span></span><br><span class="line"><span class="number">15</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>2.尾递归：每轮直接return，不需要保存当前环境供后续处理。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">sum</span><span class="params">(<span class="type">int</span> n,<span class="type">int</span> total = <span class="number">0</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (n==<span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> total;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>(n<span class="number">-1</span>,total+n);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其计算过程如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sum</span>(<span class="number">5</span>, <span class="number">0</span>)</span><br><span class="line"><span class="built_in">sum</span>(<span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line"><span class="built_in">sum</span>(<span class="number">3</span>, <span class="number">9</span>)</span><br><span class="line"><span class="built_in">sum</span>(<span class="number">2</span>, <span class="number">12</span>)</span><br><span class="line"><span class="built_in">sum</span>(<span class="number">1</span>, <span class="number">14</span>)</span><br><span class="line"><span class="built_in">sum</span>(<span class="number">0</span>, <span class="number">15</span>)</span><br><span class="line"><span class="number">15</span></span><br></pre></td></tr></table></figure>
<p>利用尾递归求斐波那契数列：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">fib</span><span class="params">(<span class="type">int</span> x1,<span class="type">int</span> x2,<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (n==<span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (n==<span class="number">1</span> || n==<span class="number">2</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(n==<span class="number">3</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> x1+x2;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">fib</span>(x2,x1+x2,n<span class="number">-1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>计算过程如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">fib</span>(<span class="number">6</span>)=<span class="built_in">fib</span>(<span class="number">1</span>,<span class="number">1</span>,<span class="number">6</span>)</span><br><span class="line"><span class="built_in">fib</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line"><span class="built_in">fib</span>(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"><span class="built_in">fib</span>(<span class="number">3</span>,<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line"><span class="number">8</span></span><br></pre></td></tr></table></figure>
<p>观察变量<span
class="math inline">\(n\)</span>的变化可知，时间复杂度<span
class="math inline">\(T(n)=O(n)\)</span>,辅助空间只需要<span
class="math inline">\(x1,x2\)</span>,因此空间复杂度<span
class="math inline">\(S(n)=O(1)\)</span>.</p>
<h4 id="方法三非递归迭代">方法三、非递归(迭代)</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">fib</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (n==<span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(n==<span class="number">1</span>||n==<span class="number">2</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> x=<span class="number">1</span>,y=<span class="number">1</span>;<span class="type">int</span> tmp = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>;i &lt; n<span class="number">-2</span>;i++)</span><br><span class="line">        &#123;</span><br><span class="line">            tmp = x+y;</span><br><span class="line">            x = y;</span><br><span class="line">            y = tmp;  </span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> y;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>观察变量<span
class="math inline">\(n\)</span>的变化可知，时间复杂度<span
class="math inline">\(T(n)=O(n)\)</span>,辅助空间只需要<span
class="math inline">\(x,y,i,tmp\)</span>,因此空间复杂度<span
class="math inline">\(S(n)=O(1)\)</span>.</p>
<h4 id="方法四矩阵快速幂">方法四、矩阵快速幂</h4>
<ul>
<li><h5 id="快速幂">快速幂：</h5>
<p>在计算<span class="math inline">\(a^n\)</span>时，若使用<span
class="math inline">\(a^n=a\ \cdot a \ \cdot a...a
(n个)\)</span>方法，则时间复杂度为<span
class="math inline">\(O(n)\)</span>;快速幂的思想是，将<span
class="math inline">\(n\)</span>写成二进制形式</p>
<p><span
class="math inline">\((n_tn_{t-1}...n_1n_0)_2\)</span>,那么<span
class="math inline">\(a^n = a^{n_t\cdot 2^t}*a^{n_{t-1}\cdot
2^{t-1}}*...*a^{n_0\cdot 2^0}\)</span>,其中<span
class="math inline">\(n_i\in\{0,1\}\)</span></p>
<p>因此我们只需要将<span class="math inline">\(2^0\ 2^1....2^{\left
\lfloor log_{2}{n} \right
\rfloor}\)</span>算出，再将二进制位为1对应的幂运算结果相乘即可，时间复杂度为<span
class="math inline">\(O(log n)\)</span>。</p>
<p>比如：<img src="/2024/04/01/斐波那契数列算法总结/image-20240403132154215.png"  alt="image-20240403132154215" style="zoom:67%;" /><img src="/2024/04/01/斐波那契数列算法总结/image-20240403132250525.png"  alt="image-20240403132250525" style="zoom:67%;" /></p>
<p>快速幂分为递归和迭代两种实现方式，两者理论时间复杂度都为<span
class="math inline">\(O(logn)\)</span>,通常情况下，迭代性能较好。</p>
<h5 id="递归版本">(1)递归版本</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">double</span> <span class="title">quickPow</span><span class="params">(<span class="type">double</span> a,<span class="type">long</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (n==<span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (n&lt;<span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> (<span class="number">1.0</span>/<span class="built_in">quickPow</span>(a,-n));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">long</span> <span class="type">long</span> res = <span class="built_in">quickPow</span>(a,n/<span class="number">2</span>);</span><br><span class="line">        <span class="keyword">if</span> (n%<span class="number">2</span>==<span class="number">1</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> res * res *a;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> res * res;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如：计算<span
class="math inline">\(2^5\)</span>的调用及计算过程如下：</p>
<p><img src="/2024/04/01/斐波那契数列算法总结/image-20240403135754758.png"  alt="image-20240403135754758" style="zoom: 25%;" /></p></li>
</ul>
<h5 id="迭代版本">(2)迭代版本</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">double</span> <span class="title">quickPow</span><span class="params">(<span class="type">long</span> <span class="type">long</span> a, <span class="type">long</span>  n)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (n&lt;<span class="number">0</span>) <span class="keyword">return</span> <span class="built_in">quickPow</span>(a,-n);</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> res = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (n &gt; <span class="number">0</span>) </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (n &amp; <span class="number">1</span>)<span class="comment">//相当于b%2==1</span></span><br><span class="line">        &#123;</span><br><span class="line">            res = res * a;</span><br><span class="line">        &#125;</span><br><span class="line">        a = a * a;</span><br><span class="line">        n &gt;&gt;= <span class="number">1</span>;<span class="comment">//右移一位相当于b=b/2;</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<p>如计算<span class="math inline">\(2^{10}\)</span>的迭代过程如下：</p>
<p><img src="/2024/04/01/斐波那契数列算法总结/image-20240403142939144.png"  alt="image-20240403142939144" style="zoom: 33%;" /></p>
<ul>
<li><h3 id="快速矩阵幂">快速矩阵幂</h3>
<p>由斐波那契数列的递推公式可知：</p>
<p><span
class="math inline">\(\begin{bmatrix}f(n)\\f(n-1)\end{bmatrix}=\begin{bmatrix}1&amp;1\\1&amp;0\end{bmatrix}\begin{bmatrix}f(n-1)\\f(n-2)\end{bmatrix}=\cdot
\cdot \cdot =\begin{bmatrix}
1&amp;1\\1&amp;0\end{bmatrix}^{n-1}\begin{bmatrix}f(1)\\f(0)\end{bmatrix}=\cdot
\cdot \cdot =\begin{bmatrix}
1&amp;1\\1&amp;0\end{bmatrix}^{n-1}\begin{bmatrix}
1\\0\end{bmatrix}\)</span></p>
<p>故，令<span class="math inline">\(A=\begin{bmatrix}
1&amp;1\\1&amp;0\end{bmatrix}^{n-1}\)</span>，则<span
class="math inline">\(f(n)=A[0][0]\)</span></p>
<p>矩阵快速幂和快速幂的方法和思想一致，都是将先前的计算结果保存下来以供后续使用，减小计算量，只需将<span
class="math inline">\(1\)</span>换为单位矩阵，将常熟换为矩阵<span
class="math inline">\(A\)</span>即可.</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 矩阵乘法函数</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">multiply</span><span class="params">(<span class="type">long</span> <span class="type">long</span> a[<span class="number">2</span>][<span class="number">2</span>], <span class="type">long</span> <span class="type">long</span> b[<span class="number">2</span>][<span class="number">2</span>])</span> </span>&#123;</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> mul[<span class="number">2</span>][<span class="number">2</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; <span class="number">2</span>; j++) &#123;</span><br><span class="line">            mul[i][j] = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">0</span>; k &lt; <span class="number">2</span>; k++)</span><br><span class="line">                mul[i][j] += a[i][k] * b[k][j];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 将乘法结果复制回a矩阵</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; <span class="number">2</span>; j++) &#123;</span><br><span class="line">            a[i][j] = mul[i][j];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 快速矩阵幂算法</span></span><br><span class="line"><span class="function"><span class="type">long</span> <span class="type">long</span> <span class="title">matrixPower</span><span class="params">(<span class="type">long</span> <span class="type">long</span> matrix[<span class="number">2</span>][<span class="number">2</span>], <span class="type">long</span> <span class="type">long</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> result[<span class="number">2</span>][<span class="number">2</span>] = &#123;&#123;<span class="number">1</span>, <span class="number">0</span>&#125;, &#123;<span class="number">0</span>, <span class="number">1</span>&#125;&#125;; <span class="comment">// 单位矩阵</span></span><br><span class="line">    <span class="keyword">while</span> (n &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (n &amp; <span class="number">1</span>)</span><br><span class="line">            <span class="built_in">multiply</span>(result, matrix);</span><br><span class="line">        <span class="built_in">multiply</span>(matrix, matrix);</span><br><span class="line">        n &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> result[<span class="number">0</span>][<span class="number">0</span>];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 计算斐波那契数</span></span><br><span class="line"><span class="function"><span class="type">long</span> <span class="type">long</span> <span class="title">fibonacci</span><span class="params">(<span class="type">long</span> <span class="type">long</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (n == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> matrix[<span class="number">2</span>][<span class="number">2</span>] = &#123;&#123;<span class="number">1</span>, <span class="number">1</span>&#125;, &#123;<span class="number">1</span>, <span class="number">0</span>&#125;&#125;;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">matrixPower</span>(matrix, n - <span class="number">1</span>);</span><br><span class="line">    </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">   </span><br><span class="line">    cout &lt;&lt;<span class="built_in">fibonacci</span>(<span class="number">7</span>) &lt;&lt; endl;</span><br><span class="line">    <span class="built_in">system</span>(<span class="string">&quot;pause&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>分析程序知时间复杂度为<span
class="math inline">\(O(logn)\)</span>,空间复杂度为<span
class="math inline">\(O(1)\)</span></p>
<h3 id="总结">总结</h3>
<p>（1)朴素递归：<span
class="math inline">\(T(n)=O(fib(n))=O(\frac{1}{\sqrt{5}} \left [
(\frac{1+\sqrt[]{5} }{2} )^{n}- (\frac{1-\sqrt[]{5} }{2} )^{n}\right
])=O((\frac{1+\sqrt[]{5} }{2} )^{n})\)</span>,<span
class="math inline">\(S(n)=O(n)\)</span></p>
<ol start="2" type="1">
<li>尾递归：<span class="math inline">\(T(n)=O(n)\)</span>,<span
class="math inline">\(S(n)=O(1)\)</span></li>
</ol>
<p>(3)非递归（迭代）：<span
class="math inline">\(T(n)=O(n)\)</span>,<span
class="math inline">\(S(n)=O(1)\)</span></p>
<p>（4) 矩阵快速幂：<span
class="math inline">\(T(n)=O(logn)\)</span>,<span
class="math inline">\(S(n)=O(1)\)</span></p></li>
</ul>
]]></content>
      <categories>
        <category>编程算法</category>
      </categories>
      <tags>
        <tag>算法、数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2024/03/31/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very
first post. Check <a href="https://hexo.io/docs/">documentation</a> for
more info. If you get any problems when using Hexo, you can find the
answer in <a
href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or
you can ask me on <a
href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="hello-hexo">Hello Hexo</h2>
<h2 id="quick-start">Quick Start</h2>
<h3 id="create-a-new-post">Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a
href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="run-server">Run server</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="generate-static-files">Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a
href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="deploy-to-remote-sites">Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a
href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
  </entry>
  <entry>
    <title>第三章、强化学习基本概念</title>
    <url>/2024/04/01/%E7%AC%AC%E4%B8%89%E7%AB%A0%E3%80%81%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<h3 id="马尔可夫决策过程">1. 马尔可夫决策过程</h3>
<p>马尔可夫决策过程：<span class="math inline">\(MDP,Markov Decision
Process\)</span> <strong>智能体</strong>：做动作或决策的主体；
<strong>环境</strong>：与智能体交互的对象；</p>
<h3 id="状态动作奖励">2. 状态、动作、奖励</h3>
<p><strong>状态</strong>：对当前时刻环境的概括,记作<span
class="math inline">\(s_t\)</span>，是做决策的依据；如：棋盘上的格局
<strong>状态空间</strong>：所有可能存在的状态的集合，记作<span
class="math inline">\(\mathcal{S}\)</span>;状态空间可离散、可连续；可有限、可无限
<strong>动作</strong>：智能体基于当前状态所做出的决策，动作的选取可以是确定性的、也可以是随机性的（多数情况下为随机性的），即给定一个概率分布（一个加和为1的概率向量），智能体按照这个概率分布选取一个动作
<strong>动作空间</strong>：所有可能动作的集合，记作<span
class="math inline">\(\mathcal{A}\)</span>;同样，离散、连续、有限、无限皆可
<strong>奖励</strong>：智能体在执行一个动作后，环境返回给智能体的一个数值；奖励函数一般由自己设计及定义，记作<span
class="math inline">\(r(s_t,a_t,s_{t+1})\)</span>或<span
class="math inline">\(r(s_t,a_t)\)</span>;我们总是假设奖励函数是有界的，即对于所有<span
class="math inline">\(a_t\in\mathcal{A}\)</span>, <span
class="math inline">\(s_t,s_{t+1}\)</span>,有<span
class="math inline">\(|r(s_t,a_t,s_{t+1})|&lt;\infty\)</span>，否则得到一个正负无穷大的奖励后就没必要继续了。</p>
<h3 id="状态转移">3.状态转移</h3>
<p><strong>状态转移</strong>：智能体从当前<span
class="math inline">\(t\)</span>时刻的状态<span
class="math inline">\(s\)</span>转移到下一刻的状态<span
class="math inline">\(s&#39;\)</span>的过程；我们用<strong>状态转移函数</strong>来描述状态转移，记作：
<span
class="math display">\[p_t(s&#39;|s,a)=P(S_{t+1}=s&#39;|S_t=s,A_t=a)\]</span>
表示发生下述事件的概率：在当前状态<span
class="math inline">\(s\)</span>,智能体执行动作<span
class="math inline">\(a\)</span>,下一刻环境的状态变成<span
class="math inline">\(s&#39;\)</span>，这个值必不恒等于1，因为状态转移存在随机性。
<strong>确定性状态转移</strong>：环境中不存在随机性，下一个状态<span
class="math inline">\(s&#39;\)</span>完全由<span
class="math inline">\(s,a\)</span>决定： <span
class="math display">\[p_t(s&#39;|s,a)=\begin{cases}
  &amp; \text{ 1 , if } \tau_t(s,a) = s&#39; \\
  &amp; \text{ 0 , otherwise }
\end{cases}\]</span>
<strong>随机性状态转移</strong>：环境中存在随机性，比如，在玛丽欧游戏中你可以控制玛丽欧怎么移动，但敌人怎么移动则无法确定，这就是下一刻状态不确定的缘由。</p>
<h3 id="策略">4.策略</h3>
<p><strong>策略</strong>：如何根据观测到的状态做出决策，即如何从动作空间中选取一个动作。
<strong>随机性策略</strong>：<span
class="math inline">\(\pi(a|s)=P(A=a|S=s)\)</span>,即给定当前状态条件下采取各个动作的概率，也就是加和为1的向量。
<strong>确定性策略</strong>：记作<span
class="math inline">\(\mu:\mathcal{S}\to\mathcal{A}\)</span>,即动作<span
class="math inline">\(a\)</span>完全由状态<span
class="math inline">\(s\)</span>决定:<span
class="math inline">\(a=\mu(s)\)</span></p>
<p><strong>智能体与环境交互的流程</strong>：观测到当前状态<span
class="math inline">\(s\)</span>，用策略<span class="math inline">\(\pi
(a|s)\)</span>算出所有动作的概率并随机抽样，得到其中一个动作<span
class="math inline">\(a\)</span></p>
<p>,环境通过状态转移函数<span
class="math inline">\(p_t(s&#39;|s,a)\)</span>(这也是一个概率分布)随机生成新的状态<span
class="math inline">\(s’\)</span>，并向智能体返回一个奖励<span
class="math inline">\(r(s,a,s’)\)</span>。</p>
<h3 id="马尔可夫性质markov-property">5.马尔可夫性质（Markov
property）</h3>
<p>马尔可夫性，即下一时刻状态<span
class="math inline">\(S_{t+1}\)</span>仅仅依赖于当前状态<span
class="math inline">\(S_t\)</span>和动作<span
class="math inline">\(A_t\)</span>,而不依赖于过去的状态和动作： <span
class="math display">\[P(S_{t+1}|S_t,A_t)=P(S_{t+1}|S_1,A_1,S_2,A_2,...,S_t,A_t)\]</span>
<strong>轨迹</strong>：在一个回合（从开始到结束）中智能体观测到的所有状态、动作、奖励：<span
class="math inline">\(s_1,a_1,r_1,s_2,a_2,r_2,s_3,a_3,r_3...\)</span></p>
<h3 id="回报与折扣回报">6.回报与折扣回报</h3>
<p><strong>回报</strong>：从当前时刻开始到本回合结束所有奖励的总和，也叫作累积奖励。假设本回合在时刻<span
class="math inline">\(n\)</span>结束，则<span
class="math inline">\(t\)</span>时刻的回报定义为： <span
class="math display">\[U_t=R_{t\to end}=R_t+R_{t+1}+...+R_n\]</span>
<strong>折扣回报</strong>：越久远的未来的回报越不重要，所以应该随时间乘上相应的折扣率<span
class="math inline">\(\gamma\in[0,1]\)</span>，折扣回报： <span
class="math display">\[U_t=R_t+\gamma \cdot R_{t+1}+\gamma^2 \cdot
R_{t+2}+...\]</span> 可以将其理解为得到了一个新的奖励函数，<span
class="math inline">\(R_{t+i}=\gamma^i\cdot R_{t+i}\)</span></p>
<h3 id="价值函数重中之重">7.价值函数（重中之重！！！）</h3>
<p>价值函数是回报的期望，价值函数值越大，说明现状越有利；
<strong>动作价值函数</strong>： <span
class="math display">\[Q_{\pi}(s_t,a_t)=E_{S_{t+1},A_{t+1},...,S_n,A_n}[U_t|S_t=s_t,A_t=a_t]\]</span>
表示已经观测到了<span
class="math inline">\(S_t,A_t\)</span>的值，即观测到状态<span
class="math inline">\(s_t\)</span>,选中动作<span
class="math inline">\(a_t\)</span>，原来<span
class="math inline">\(U_t\)</span>中的随机性来自<span
class="math inline">\(t+1\)</span>时刻起所有的状态和动作：<span
class="math inline">\(S_{t+1},A_{t+1},...,S_n,A_n\)</span>,而动作价值函数对它们求期望，简单理解就是找出它们的所有情况，算出<span
class="math inline">\(U_t\)</span>求平均，这样就消除它们的影响。 <span
class="math inline">\(\qquad\)</span><span
class="math inline">\(t\)</span>时刻的动作价值函数<span
class="math inline">\(Q_\pi(s_t,a_t)\)</span>依赖于以下三个因素：
（1）当前状态<span
class="math inline">\(s_t\)</span>：当前状态越好，<span
class="math inline">\(Q_\pi(s_t,a_t)\)</span>越大 （2）当前动作<span
class="math inline">\(a_t\)</span>：智能体执行的动作越好，<span
class="math inline">\(Q_\pi(s_t,a_t)\)</span>越大 （3）策略函数<span
class="math inline">\(\pi\)</span>：<span
class="math inline">\(S_{t+1},A_{t+1},...,S_n,A_n\)</span>由策略决定，所以对它们求期望最终的结果受到策略的影响。
<strong>最优动作价值函数</strong>： 为了排除策略<span
class="math inline">\(\pi\)</span>的影响，可以使： <span
class="math display">\[\pi^*=\mathop{argmax}\limits_{\pi}
Q_\pi(s_t,a_t),\forall s_t\in\mathcal{S},a_t\in\mathcal{A}\]</span>
即选取一个当前为任何状态、执行任何动作的情况下都最优的策略，这样策略就确定了，也就排除了策略<span
class="math inline">\(\pi\)</span>的影响，<span
class="math inline">\(Q_*(s_t,a_t)\)</span>就是最优动作价值函数。
<strong>状态价值函数</strong>: <span
class="math display">\[V_\pi(s_t)=E_{A_t\sim\pi(\cdot|s_t)}[Q_\pi(s_t,A_t)]=\sum_{a\in\mathcal{A}}^{}\pi(a|s_t)
\cdot Q_\pi(s_t,a)\]</span>
状态价值函数可以理解为在动作价值函数的基础上，动作<span
class="math inline">\(A_t\)</span>不再确定，而是随机变量，对动作<span
class="math inline">\(A_t\)</span>求期望以消除动作的影响，使得状态价值函数只依赖于策略函数<span
class="math inline">\(\pi\)</span>和状态<span
class="math inline">\(s_t\)</span>的好坏</p>
<p><strong>两者比较</strong>： <span class="math display">\[
Q_{\pi}(s_t,a_t)=E_{S_{t+1},A_{t+1},...,S_n,A_n}[U_t|S_t=s_t,A_t=a_t]
\]</span></p>
<p><span class="math display">\[
V_{\pi}(s_t)=E_{A_t,S_{t+1},A_{t+1},...,S_n,A_n}[U_t|S_t=s_t]
\]</span></p>
<p>强化学习分为（1）基于模型的方法 （2）无模型方法</p>
<p>无模型方法：价值学习、策略学习</p>
<p>基于模型的方法：AlphaGo</p>
]]></content>
      <categories>
        <category>深度强化学习读书笔记</category>
      </categories>
      <tags>
        <tag>人工智能、强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>第一章、机器学习基础</title>
    <url>/2024/04/05/%E7%AC%AC%E4%B8%80%E7%AB%A0%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<h3 id="线性模型">1.1 线性模型</h3>
<h4 id="线性回归linear-regression">1.1.1 线性回归（Linear
Regression）</h4>
<p>线性回归简单理解即”拟合一条曲线“，可通过<span
class="math inline">\(x\)</span>的值预测<span
class="math inline">\(y\)</span>值 <span class="math display">\[
\hat{y}=f(x;\hat{w},\hat{b})=x^T\hat{w}+\hat{b}
\]</span></p>
<ul>
<li><p>训练集：用于优化模型参数</p></li>
<li><p>验证集：用于优化模型超参数，如学习率、正则化系数等；</p></li>
<li><p>测试集：用于评估模型性能</p>
<p><strong>线性回归从零开始实现</strong>，<a
href="https://github.com/kumudlakara/Medium-codes/blob/main/linear_regression/house_price_data.txt">数据集下载</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># variables to store mean and standard deviation for each feature</span></span><br><span class="line">mu = []</span><br><span class="line">std = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># load data from the filename</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_data</span>(<span class="params">filename</span>):</span><br><span class="line">	df = pd.read_csv(filename, sep=<span class="string">&quot;,&quot;</span>, index_col=<span class="literal">False</span>)</span><br><span class="line">	df.columns = [<span class="string">&quot;house size&quot;</span>, <span class="string">&quot;rooms&quot;</span>, <span class="string">&quot;price&quot;</span>]</span><br><span class="line">	data = np.array(df, dtype=<span class="built_in">float</span>)</span><br><span class="line">	plot_data(data[:, :<span class="number">2</span>], data[:, -<span class="number">1</span>])</span><br><span class="line">	normalize(data)</span><br><span class="line">	<span class="keyword">return</span> data[:, :<span class="number">2</span>], data[:, -<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># draw the data[house size,price]</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_data</span>(<span class="params">x, y</span>):</span><br><span class="line">	plt.xlabel(<span class="string">&#x27;house size&#x27;</span>)</span><br><span class="line">	plt.ylabel(<span class="string">&#x27;price&#x27;</span>)</span><br><span class="line">	plt.plot(x[:, <span class="number">0</span>], y, <span class="string">&#x27;bo&#x27;</span>)</span><br><span class="line">	plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># normalize the data</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">normalize</span>(<span class="params">data</span>):</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, data.shape[<span class="number">1</span>] - <span class="number">1</span>):</span><br><span class="line">		mu.append(np.mean(data[:, i]))</span><br><span class="line">		std.append(np.std(data[:, i]))</span><br><span class="line">		data[:, i] = ((data[:, i] - np.mean(data[:, i])) / np.std(data[:, i]))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># matrix multiply</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">h</span>(<span class="params">x, theta</span>):</span><br><span class="line">	<span class="keyword">return</span> np.matmul(x, theta)</span><br><span class="line"></span><br><span class="line"><span class="comment"># calculate the cost_function</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cost_function</span>(<span class="params">x, y, theta</span>):</span><br><span class="line">	<span class="keyword">return</span> ((h(x, theta) - y).T @ (h(x, theta) - y)) / (<span class="number">2</span> * y.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># calculate the gradient</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient_descent</span>(<span class="params">x, y, theta, learning_rate=<span class="number">0.1</span>, num_epochs=<span class="number">10</span></span>):</span><br><span class="line">	m = x.shape[<span class="number">0</span>]</span><br><span class="line">	J_all = []</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">		h_x = h(x, theta)</span><br><span class="line">		cost_ = (<span class="number">1</span> / m) * (x.T @ (h_x - y))</span><br><span class="line">		theta = theta - (learning_rate) * cost_</span><br><span class="line">		J_all.append(cost_function(x, y, theta))</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> theta, J_all</span><br><span class="line"></span><br><span class="line"><span class="comment"># draw the change of the cost</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_cost</span>(<span class="params">J_all, num_epochs</span>):</span><br><span class="line">	plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">	plt.ylabel(<span class="string">&#x27;Cost&#x27;</span>)</span><br><span class="line">	plt.plot(num_epochs, J_all, <span class="string">&#x27;m&#x27;</span>, linewidth=<span class="string">&quot;5&quot;</span>)</span><br><span class="line">	plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">theta, x</span>):</span><br><span class="line">	x[<span class="number">0</span>] = (x[<span class="number">0</span>] - mu[<span class="number">0</span>]) / std[<span class="number">0</span>]</span><br><span class="line">	x[<span class="number">1</span>] = (x[<span class="number">1</span>] - mu[<span class="number">1</span>]) / std[<span class="number">1</span>]</span><br><span class="line">	y = theta[<span class="number">0</span>] + theta[<span class="number">1</span>] * x[<span class="number">0</span>] + theta[<span class="number">2</span>] * x[<span class="number">1</span>]</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&quot;Price of house: &quot;</span>, y[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x, y = load_data(<span class="string">&quot;house_price_data.txt&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x和y的形状分别为&quot;</span>,x.shape,y.shape)</span><br><span class="line">y = np.reshape(y, (<span class="number">46</span>, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># 加一列全1向量</span></span><br><span class="line">x = np.hstack((np.ones((x.shape[<span class="number">0</span>], <span class="number">1</span>)), x))</span><br><span class="line">theta = np.zeros((x.shape[<span class="number">1</span>], <span class="number">1</span>))</span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line">num_epochs = <span class="number">10000</span></span><br><span class="line">theta, J_all = gradient_descent(x, y, theta, learning_rate, num_epochs)</span><br><span class="line">J = cost_function(x, y, theta)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Cost: &quot;</span>, J)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Parameters: &quot;</span>, theta)</span><br><span class="line"></span><br><span class="line"><span class="comment"># for testing and plotting cost</span></span><br><span class="line">n_epochs = []</span><br><span class="line">jplot = []</span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;J_all形状&quot;</span>,np.array(J_all).shape)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> J_all:</span><br><span class="line">	jplot.append(i[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">	n_epochs.append(count)</span><br><span class="line">	count += <span class="number">1</span></span><br><span class="line">jplot = np.array(jplot)</span><br><span class="line">n_epochs = np.array(n_epochs)</span><br><span class="line">plot_cost(jplot, n_epochs)</span><br><span class="line"></span><br><span class="line">test(theta, [<span class="number">1203</span>, <span class="number">3</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="逻辑斯蒂回归logistic-regression">1.1.2 逻辑斯蒂回归(Logistic
Regression)</h4>
<p>逻辑斯蒂回归=线性回归+<span
class="math inline">\(sigmoid\)</span>函数，主要用于处理二分类问题，<span
class="math inline">\(sigmoid\)</span>函数可将任何实数映射到0和1之间，以表示属于两类中某一类别的概率，可设置阈值<span
class="math inline">\(\delta\)</span>进行类别的最终判断。 <span
class="math display">\[
f(x;w,b)=sigmoid(y)=sigmoid(x^Tw+b)=\frac{1}{1+e^{-(x^Tw+b)}}
\]</span></p>
<h4 id="交叉熵损失函数cross-entropy-loss-function">1.1.3
交叉熵损失函数(Cross Entropy Loss Function)</h4>
<p><strong>KL散度</strong>，也称相对熵，用于衡量两个概率分布之间的差异，在离散情况下，使用向量<span
class="math inline">\(p=[p_1,p_2,\cdot\cdot\cdot,p_m]^T\)</span>,<span
class="math inline">\(q=[q_1,q_2,\cdot\cdot\cdot,q_m]^T\)</span></p>
<p>表示两个<span class="math inline">\(m\)</span>维的离散概率分布，则
<span class="math display">\[
KL(p,q)=H(p,q)-H(p)=\sum_{j=1}^{m} p_j\cdot ln\frac{p_j}{q_j}
\]</span> 其中交叉熵<span
class="math inline">\(H(p,q)=-\sum_{j=1}^{m}p_j\cdot lnq_j\)</span>,</p>
<p>信息熵<span class="math inline">\(H(p)=-\sum_{j=1}^{m}p_j\cdot
lnp_j\)</span></p>
<p>当概率分布<span
class="math inline">\(p\)</span>固定时，也就是说我们要让<span
class="math inline">\(q\)</span>尽量接近<span
class="math inline">\(p\)</span>时,最小化交叉熵即可，这也就是为什么交叉熵损失函数有效的原因。</p>
<h4 id="softmax分类器">1.1.4 softmax分类器</h4>
<p>softmax分类=线性函数+softmax激活函数</p>
<p>其中线性函数的结果为向量，再通过softmax将这个向量映射到加和为1的概率分布；
<span class="math display">\[
\pi \in R^k = softmax(z\in R^k)=softmax(W\in R^{k\times d} \cdot x\in
R^{d\times1})+b\in R^{k\times1}
\]</span> 其中<span
class="math inline">\(softmax(z)=\frac{1}{\sum\limits_{l=1}^{k}exp(z_l)}[exp(z_1),exp(z_2),\cdot\cdot\cdot,exp(z_k)]\)</span></p>
<p>通常情况下，需要对矩阵<span
class="math inline">\(W\)</span>和向量<span
class="math inline">\(b\)</span>做规范化，使得<span
class="math inline">\(\sum\limits_{j=1}^{k}w_j=0,\sum\limits_{j=1}^{k}b_j=0\)</span>,<span
class="math inline">\(w_j\)</span>为矩阵<span
class="math inline">\(W\)</span>的第<span
class="math inline">\(j\)</span>行，即矩阵<span
class="math inline">\(W\)</span>的每列和为0，向量<span
class="math inline">\(b\)</span>和为0，这可以通过全员减去平均值再除以标准差来达成。</p>
<h5 id="常见的数据标准化方法总结">常见的数据标准化方法总结：</h5>
<ul>
<li><p><span class="math inline">\(min\_max\)</span>: <span
class="math inline">\(x_{new}=\frac{x-x_{min}}{x_{max}-x_{min}}\)</span>,映射到<span
class="math inline">\([0,1]\)</span>;</p></li>
<li><p><span class="math inline">\(z\_score\)</span>: <span
class="math inline">\(x_{new}=\frac{x-\mu}{\delta}\)</span>,映射到标准正态分布；</p></li>
<li><p>正数归一化： <span
class="math inline">\(x_{new}=\frac{x}{x_1+x_2+...+x_n}\)</span>,映射到<span
class="math inline">\([0,1]\)</span>;</p></li>
<li><p>中心化： <span
class="math inline">\(x_{new}=x-\mu\)</span>,使得均值为0</p></li>
</ul>
<h3 id="神经网络简介">1.2 神经网络简介</h3>
<h4 id="全连接层感知机">1.2.1 全连接层（感知机）</h4>
<p><span class="math display">\[
{x}’=\sigma(z)=\sigma(Wx+b)
\]</span></p>
<p>即线性函数+激活函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(nn.Flatten(), nn.Linear(<span class="number">784</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_weights</span>(<span class="params">m</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear:</span><br><span class="line">        nn.init.normal_(m.weight, std=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">net.apply(init_weights);</span><br><span class="line"></span><br><span class="line">loss = nn.CrossEntropyLoss(reduction=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line"></span><br><span class="line">trainer = torch.optim.SGD(net.parameters(), lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">num_epochs = <span class="number">10</span></span><br><span class="line">d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)</span><br><span class="line">d2l.predict_ch3(net,test_iter)</span><br></pre></td></tr></table></figure>
<h4 id="卷积神经网络">1.2.2 卷积神经网络</h4>
<p>卷积神经网络的输入通常是矩阵或三阶张量，CNN从中提取特征并输出提取的特征向量。</p>
<h3 id="梯度下降gdgradient-descent">1.3 梯度下降（GD，gradient
descent）</h3>
<ul>
<li>目标函数关于某个参数变量的梯度的形状一定与这个参数变量的形状相同；</li>
<li>梯度的方向是函数上升最快的方向，因此其负方向是下降最快的方向；</li>
<li><strong>1.梯度下降</strong>：每epoch计算所有样本的损失函数的平均再做梯度下降；（用于非凸问题存在鞍点，且计算量为SGD的n倍）</li>
<li><strong>2.随机梯度下降</strong>：每epoch从样本集合中选取一个样本计算损失函数再做梯度下降；</li>
<li><strong>3.小批量随机梯度下降</strong>：每epoch从样本集合中随机抽取batch_size个样本计算损失函数求平均再做梯度下降；</li>
<li>反向传播：任何一个计算过程都可以构建其计算图，从计算图尾部用梯度下降向前传播，更新参数；</li>
</ul>
]]></content>
      <categories>
        <category>深度强化学习读书笔记</category>
      </categories>
      <tags>
        <tag>机器学习、强化学习、人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>第二章、蒙特卡洛方法</title>
    <url>/2024/03/31/%E7%AC%AC%E4%BA%8C%E7%AB%A0%E3%80%81%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<ol type="1">
<li><strong>随机变量</strong>记作<span
class="math inline">\(X\)</span>,<strong>观测值</strong>记作<span
class="math inline">\(x\)</span>,观测值只是数字而已，没有随机性,如<span
class="math inline">\(P(X=0)=\frac{1}{2}\)</span>中的<span
class="math inline">\(X\)</span>为大写；</li>
<li>给定随机变量<span
class="math inline">\(X\)</span>,它的<strong>累积分布函数</strong>（即<strong>概率分布函数</strong>）（CDF）是函数<span
class="math inline">\(F_X:R\to[0,1]\)</span>,定义为： <span
class="math display">\[F_X(x)=P(X\le x)\]</span></li>
<li>对于<strong>离散概率分布</strong>，有<strong>概率质量函数</strong><span
class="math inline">\(p(x)\)</span>,假设随机变量<span
class="math inline">\(X\)</span>取值范围是集合<span
class="math inline">\(\chi\)</span> 则有： <span
class="math display">\[\sum_{x\in \chi}^{} p(x)=1\]</span> ,<span
class="math inline">\(X\)</span>的概率质量函数为<span
class="math inline">\(p(\cdot)\)</span>,则函数<span
class="math inline">\(h(X)\)</span>关于变量<span
class="math inline">\(X\)</span>的期望是 <span
class="math display">\[E_{X\sim p(\cdot)}[h(X)]=\sum_{x\in
\chi}^{}p(x)\cdot h(x)\]</span></li>
<li>对于<strong>连续概率发布</strong>，有<strong>概率密度函数</strong><span
class="math inline">\(p(x)\)</span>,随机变量<span
class="math inline">\(X\)</span>的取值范围<span
class="math inline">\(\chi\)</span>是连续集合，则有：<span
class="math display">\[\int_{-\infty }^{x} p(u)du=F_X(x)=P(X\le
x)\]</span><span class="math display">\[\int_{-\infty }^{+\infty}
p(u)du=1\]</span>,<span
class="math inline">\(X\)</span>的概率密度函数为<span
class="math inline">\(p(\cdot)\)</span>,则函数<span
class="math inline">\(h(X)\)</span>关于变量<span
class="math inline">\(X\)</span>的期望是 <span
class="math display">\[E_{X\sim p(\cdot)}[h(X)]=\int_{\chi}p(x)\cdot
h(x)dx\]</span>
<img src="/2024/03/31/第二章、蒙特卡洛方法/image-20240401134538137.png"  alt="image-20240401134538137" style="zoom: 33%;" /></li>
</ol>
<p>总的来说，就是<span
class="math inline">\(\frac{抽中次数}{总抽样数}=精确的理论概率\)</span></p>
<h3 id="例一近似pi值">例一、近似<span
class="math inline">\(\pi\)</span>值</h3>
<p><img src="/2024/03/31/第二章、蒙特卡洛方法/image-20240401134618614.png"  alt="image-20240401134618614" style="zoom:33%;" /></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">m = <span class="number">0</span></span><br><span class="line">n = <span class="number">100000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    x,y = <span class="number">2</span>*torch.rand(<span class="number">1</span>)-<span class="number">1</span>,<span class="number">2</span>*torch.rand(<span class="number">1</span>)-<span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span>  torch.<span class="built_in">pow</span>(x,<span class="number">2</span>)+ torch.<span class="built_in">pow</span>(y,<span class="number">2</span>) &lt;= <span class="number">1</span>:</span><br><span class="line">        m = m+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">pi = <span class="number">4</span> * m / n</span><br><span class="line"><span class="built_in">print</span>(pi)</span><br></pre></td></tr></table></figure>
<p>输出：3.13528 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 2.2节，蒙特卡洛近似计算圆周率。</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">approxiate_pi</span>(<span class="params">n: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="comment"># 在[-1, 1] x [-1, 1]的空间中随机取n个点。</span></span><br><span class="line">    x_lst = np.random.uniform(-<span class="number">1</span>, <span class="number">1</span>, size=n)</span><br><span class="line">    y_lst = np.random.uniform(-<span class="number">1</span>, <span class="number">1</span>, size=n)</span><br><span class="line">    <span class="comment"># 统计距离圆心距离在1以内的点。</span></span><br><span class="line">    m = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> <span class="built_in">zip</span>(x_lst, y_lst):</span><br><span class="line">        <span class="keyword">if</span> x ** <span class="number">2</span> + y ** <span class="number">2</span> &lt;= <span class="number">1</span>:</span><br><span class="line">            m += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 近似计算圆周率。</span></span><br><span class="line">    pi = <span class="number">4</span> * m / n</span><br><span class="line">    <span class="keyword">return</span> pi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    pi = approxiate_pi(<span class="number">100</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;100个点近似的圆周率：&quot;</span>, pi)</span><br><span class="line"></span><br><span class="line">    pi = approxiate_pi(<span class="number">10000</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;10000个点近似的圆周率：&quot;</span>, pi)</span><br><span class="line"></span><br><span class="line">    pi = approxiate_pi(<span class="number">1000000</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;1000000个点近似的圆周率：&quot;</span>, pi)</span><br><span class="line"></span><br></pre></td></tr></table></figure> 输出：100个点近似的圆周率： 3.08
10000个点近似的圆周率： 3.1352 1000000个点近似的圆周率： 3.141</p>
<h3 id="例二计算阴影部分面积">例二、计算阴影部分面积</h3>
<p><img src="/2024/03/31/第二章、蒙特卡洛方法/image-20240401134642296.png"  alt="image-20240401134642296" style="zoom:33%;" /></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">m = <span class="number">0</span></span><br><span class="line">n = <span class="number">100000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    x,y = <span class="number">2</span>*torch.rand(<span class="number">1</span>),<span class="number">2</span>*torch.rand(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span>  ((x-<span class="number">1</span>)**<span class="number">2</span>+(y-<span class="number">1</span>)**<span class="number">2</span>&lt;=<span class="number">1</span>) &amp; (x**<span class="number">2</span>+y**<span class="number">2</span>&gt;<span class="number">4</span>):</span><br><span class="line">        m = m+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">s = <span class="number">4</span> * m / n</span><br><span class="line"><span class="built_in">print</span>(s)</span><br></pre></td></tr></table></figure>
<p>输出：0.59632</p>
<h3 id="例三计算近似定积分期望">例三、计算近似定积分、期望</h3>
<p><strong>一元函数的定积分</strong>：抽样函数的平均值乘以区间长度，即
<span class="math display">\[
I=\int_{a}^{b}f(x)dx \approx
q_n=(b-a)\cdot\frac{1}{n}\sum\limits_{i=1}^{n}f(x_i)
\]</span>
<strong>多元函数的定积分</strong>：抽样函数的平均值乘以积分集合的体积，即
<span class="math display">\[
I=\int_{\Omega }^{}f(x)dx \approx
q_n=V\cdot\frac{1}{n}\sum\limits_{i=1}^{n}f(x_i)=\int_{\Omega}^{}dx
\cdot\frac{1}{n}\sum\limits_{i=1}^{n}f(x_i)
\]</span> 求<strong>期望</strong>：计算 <span class="math display">\[
E_{X\sim p(\cdot)}[f(X)]=\int_{\Omega}^{}p(x)\cdot f(x)dx
\]</span>
，可按照变量服从的概率分布抽样，求函数平均值即可；当然也可利用定积分，把其中的<span
class="math inline">\(f(x_i)\)</span>换成<span
class="math inline">\(p(x_i)\cdot f(x_i)\)</span>即可；</p>
<p>假设用期望计算<span
class="math inline">\(\int_{0}^{3}x^\frac{2}{3}dx\)</span> <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">q=<span class="number">0</span></span><br><span class="line">t=<span class="number">1</span></span><br><span class="line">n=<span class="number">10000</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> x ** (<span class="number">2</span>/<span class="number">3</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    a = torch.rand(<span class="number">1</span>) * <span class="number">3</span></span><br><span class="line">    q = (<span class="number">1</span>-<span class="number">1</span>/t) * q + (<span class="number">1</span>/t) * f(a)</span><br><span class="line">    t = t+<span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;期望&quot;</span>,q)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;积分&quot;</span>,<span class="number">3</span>*q)</span><br></pre></td></tr></table></figure>
输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">期望 tensor([1.2539])</span><br><span class="line">积分 tensor([3.7617])</span><br><span class="line">3.744150881493428</span><br></pre></td></tr></table></figure>
<h3 id="第二章习题2.2">第二章习题2.2</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 方法1</span></span><br><span class="line"><span class="keyword">import</span> torch </span><br><span class="line">n = <span class="number">10000</span></span><br><span class="line">f = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    x = torch.normal(mean=<span class="number">1</span>,std=<span class="number">2</span>,size=(<span class="number">1</span>,))</span><br><span class="line">    f = <span class="number">2</span>*x+<span class="number">10</span>*torch.sqrt(torch.<span class="built_in">abs</span>(x))+<span class="number">3</span>+f</span><br><span class="line"><span class="built_in">print</span>(f/n)</span><br></pre></td></tr></table></figure>
<p>输出：tensor([17.3412])</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">```python</span><br><span class="line"> <span class="comment"># 方法2</span></span><br><span class="line"><span class="keyword">import</span> torch </span><br><span class="line">n = <span class="number">10000</span></span><br><span class="line">q=<span class="number">0</span></span><br><span class="line">t=<span class="number">1</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span>  <span class="number">2</span>*x+<span class="number">10</span>*torch.sqrt(torch.<span class="built_in">abs</span>(x))+<span class="number">3</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    x = torch.normal(mean=<span class="number">1</span>,std=<span class="number">2</span>,size=(<span class="number">1</span>,))</span><br><span class="line">    q = (<span class="number">1</span>-<span class="number">1</span>/t)*q+<span class="number">1</span>/t * f(x)</span><br><span class="line">    t = t+<span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(q)</span><br></pre></td></tr></table></figure>
<p>输出：tensor([17.3020])</p>
]]></content>
      <categories>
        <category>深度强化学习读书笔记</category>
      </categories>
      <tags>
        <tag>人工智能、强化学习</tag>
      </tags>
  </entry>
</search>
